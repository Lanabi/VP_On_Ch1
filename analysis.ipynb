{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2baf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to pip install packages if necessary\n",
    "\n",
    "# pip install pandas\n",
    "# pip install krippendorff\n",
    "# pip install numpy\n",
    "# pip install statsmodels\n",
    "# pip install matplotlib\n",
    "# pip install plotly\n",
    "# pip install nltk\n",
    "# pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a759f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import pickle  # for de-serializing Python object structures\n",
    "from datetime import date, datetime # for working with dates\n",
    "import numpy as np  # for numerical computing\n",
    "import statsmodels.formula.api as sm  # for statistical modeling\n",
    "from statsmodels.tsa.stattools import adfuller # Augmented Dickey-Fuller test function\n",
    "import random # for random sampling\n",
    "import itertools # for efficient looping and list processing\n",
    "\n",
    "import matplotlib.pyplot as plt  # for plotting graphs\n",
    "import matplotlib.gridspec as gridspec  # for creating complex layouts of subplots\n",
    "import matplotlib.ticker as ticker  # for configuring tick locators and formatters\n",
    "import matplotlib.dates as mdates  # for working with dates in Matplotlib\n",
    "import matplotlib.cbook as cbook  # for utilities for working with Matplotlib\n",
    "from matplotlib.ticker import PercentFormatter, FuncFormatter  # formatters for ticks\n",
    "from matplotlib.patches import Rectangle  # for drawing rectangles in plots\n",
    "\n",
    "import plotly.graph_objects as go  # for map visualization\n",
    "from nltk.corpus import stopwords  # for retrieving stopwords in Russian\n",
    "import krippendorff  # Import the krippendorff library\n",
    "from krippendorff import alpha # to calculate krippendorff's alpha\n",
    "\n",
    "import os # to work with the libraries\n",
    "import pyarrow.feather as feather # to work with feather files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the data\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct the path to the corpus.pkl file\n",
    "corpus_path = os.path.join(current_directory, \"corpus.pkl\")\n",
    "#print(corpus_path)\n",
    "\n",
    "# Construct the path to the validation.csv file\n",
    "validation_path = os.path.join(current_directory, \"validation.csv\")\n",
    "#print(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba954dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Russian stopwords\n",
    "\n",
    "stopwords = stopwords.words('russian')\n",
    "\n",
    "# Defining punctuation marks \n",
    "punc = '''!()-[]{};\":'\"\\,<>./?@#$%^&*_~,–'''\n",
    "\n",
    "# Defining election dates for presidential terms\n",
    "el1 = date(2000, 5, 7)  # beginning of the 1st presidential term\n",
    "el2 = date(2004, 5, 8)  # beginning of the 2nd presidential term\n",
    "el3 = date(2008, 5, 8)  # Medvedev's term - beginning\n",
    "el4 = date(2012, 5, 7)  # beginning of the 3rd presidential term\n",
    "el5 = date(2018, 5, 7)  # beginning of the 4th presidential term\n",
    "\n",
    "# Storing election dates in a list\n",
    "election_dates = [el1, el2, el3, el4, el5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1565e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset \n",
    "\n",
    "df = pd.read_pickle(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First entries in the dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the columns\n",
    "\n",
    "print(\"Column names:\\n\", df.columns,'\\n')\n",
    "\n",
    "# Column 'dates'\n",
    "# The column provides the date of a news episode\n",
    "# The code below shows that the period of coverage is from 1999-12-31 to 2022-02-23\n",
    "print(\"First date:\", df.sort_values('dates').iloc[0]['dates'])\n",
    "print(\"Last date:\", df.sort_values('dates').iloc[-1]['dates'],'\\n')\n",
    "\n",
    "# Column 'text'\n",
    "# The column provides the text a news episode, including its title\n",
    "# Number of episodes in the dataset\n",
    "print(f\"{df.shape[0]} episodes\",'\\n')\n",
    "print(\"Example of an episode:\\n\", df['text'].iloc[12345],'\\n')\n",
    "\n",
    "# Column 'country'\n",
    "# The column provides a country-topic assigned by Newsmap\n",
    "print(\"Country-topics can have the following values:\\n\", sorted(list(set(df['country']))),'\\n')\n",
    "\n",
    "# Column 'sentiment_labels'\n",
    "# The column provides a sentiment label assigned by Rubert-tiny\n",
    "print(\"Three value of sentiment labels:\\n\", set(df['sentiment_labels']),'\\n')\n",
    "\n",
    "# Column 'sentiment_score'\n",
    "# The column provides a sentiment score assigned by Rubert-tiny\n",
    "print(\"Group means of sentiment scores:\\n\", df.groupby('sentiment_labels')['sentiment_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd12f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if column 'dates' in the main dataframe is in increasing order \n",
    "\n",
    "dates_increasing = df['dates'].is_monotonic_increasing\n",
    "print(\"Are the dates in increasing order?\", dates_increasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating additional columns necessary for the analysis\n",
    "\n",
    "# (Execution time: around 15 seconds)\n",
    "\n",
    "# Extract year from the 'dates' column and create a new column 'year'\n",
    "df['year'] = [i.year for i in df['dates']]\n",
    "\n",
    "# Create a column that equals one if a text mentions Putin\n",
    "df['putin'] = [1 if 'Путин' in text else 0 for text in df['text']]\n",
    "df['putin'] = df['putin'].astype(int)\n",
    "\n",
    "# Create a column for the length of text in each news episode\n",
    "df['textlength'] = [len(i.split()) for i in df['text']]\n",
    "\n",
    "# Presidential terms\n",
    "# Initialize the 'term' column with a value of 1 for all rows\n",
    "df['term'] = 1  \n",
    "# Update 'term' to 2 for rows where the 'dates' is greater than el2\n",
    "df.loc[df['dates'] > el2, 'term'] = 2\n",
    "# Update 'term' to 'Medvedev' for rows where the 'date' is greater than el3\n",
    "df.loc[df['dates'] > el3, 'term'] = 'Medvedev'\n",
    "# Update 'term' to 3 for rows where the 'date' is greater than el4\n",
    "df.loc[df['dates'] > el4, 'term'] = 3\n",
    "# Update 'term' to 4 for rows where the 'date' is greater than el5\n",
    "df.loc[df['dates'] > el5, 'term'] = 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file with validation results\n",
    "v = pd.read_csv(validation_path)\n",
    "\n",
    "# Small dataframes with the validation results are below\n",
    "# They will be used later in the script\n",
    "\n",
    "# Subset to obtain the sample to calculate the accuracy of both Rubert-tiny and Newsmap\n",
    "sa = v[v['sample'] == 'accuracy_ml']\n",
    "#  Subset to obtain the sample used to estimate the precision of Rubert Tiny\n",
    "pr = v[v['sample']=='precision_rubert']\n",
    "# Subset to obtain the sample used to estimate the precision of Newsmap\n",
    "pn = v[v['sample']=='precision_newsmap']\n",
    "# Subset to obtain the sample used to estimate the accuracy of the dictionaries\n",
    "ad = v[v['sample']=='accuracy_dict']\n",
    "# Subset to obtain the sample used to estimate the precision of the dictionaries\n",
    "pdi = v[v['sample']=='precision_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34123b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Abstract\n",
    "\n",
    "# Text in the abstract: \n",
    "# \" Using 385,981 news transcripts \" \n",
    "\n",
    "# Check if the text is the same as in validation file\n",
    "print(\"Using\", df.shape[0], 'news transcripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38438638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Introduction \n",
    "\n",
    "# Text in the article: \n",
    "# \" On average, 16% of news about events in Russia and 7% of stories about foreign affairs and events abroad\n",
    "#   refer to the ruler, which amounts to 9% and 3% of total reports from Channel One, respectively. \" \n",
    "\n",
    "df1 = df[df['putin'] == 1] # create a dataframe for only those stories that involve 'Putin' (Путин)\n",
    "\n",
    "# 16%\n",
    "putin_ru = df1[df1['country'] == 'ru'] # stories that involve Putin and labelled as covering Russia\n",
    "df_ru = df[df['country'] == 'ru'] # all stories labelled as covering Russia\n",
    "percentage_putin_ru = round((putin_ru.shape[0] / df_ru.shape[0])*100)\n",
    "print(f\"{percentage_putin_ru}% of news about events in Russia\")\n",
    "\n",
    "# 7%\n",
    "putin_foreign = df1[df1['country'] != 'ru'] # stories that involve Putin and labelled as not covering Russia\n",
    "df_f = df[df['country'] != 'ru'] # all stories labelled as not covering Russia\n",
    "percentage_putin_foreign = round((putin_foreign.shape[0] / df_f.shape[0])*100)\n",
    "print(f\"{percentage_putin_foreign}% of stories about foreign affairs\")\n",
    "\n",
    "# 9%\n",
    "percentage_total_ru = round((putin_ru.shape[0] / df.shape[0])*100)\n",
    "print(f\"which amounts to {percentage_total_ru}%\")\n",
    "\n",
    "# 3%\n",
    "percentage_total_foreign = round((putin_foreign.shape[0] / df.shape[0])*100)\n",
    "print(f\"and {percentage_total_foreign}% of total reports from Channel One\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328beed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Section: Introduction \n",
    "\n",
    "# Text in the article:\n",
    "# \" At the same time, I document a steady and significant increase—from 3% in 2012 to 18% in 2021\n",
    "#   —in the share of news about foreign affairs and events originating abroad that mentioned the ruler. \" \n",
    "\n",
    "# The shares of news about foreign affairs and events originating abroad that mentioned the ruler\n",
    "# Define a list 'years' containing years from 2012 to 2021\n",
    "years = [year for year in range(2012, 2022)]\n",
    "\n",
    "# Iterate through each year in the list 'years'\n",
    "for year in years:\n",
    "    # Subset the DataFrame 'df' for the current year\n",
    "    df1 = df[df['year'] == year]\n",
    "\n",
    "    # Subset further to include only rows where the 'country' column is not 'ru' (foreign news)\n",
    "    f = df1[df1['country'] != 'ru']\n",
    "\n",
    "    # Further subset to include only rows where the 'putin' column is 1 (foreign stories that mention Putin)\n",
    "    fp = f[f['putin'] == 1]\n",
    "\n",
    "    # Calculate the percentage of foreign stories mentioning Putin compared to all foreign news this year\n",
    "    percentage_foreign_with_putin = round((fp.shape[0] / f.shape[0]) * 100)\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"and {percentage_foreign_with_putin}% was the share of news reports about foreign affairs and events abroad that mentioned the ruler in {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923de4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Data and Estimation Strategy\"\n",
    "\n",
    "# Text in the article: \n",
    "# \" My analysis relies on a corpus comprised of 385,981 transcripts of news reports\n",
    "#   transmitted on Channel One between December 31,1999, the day when Putin became an acting\n",
    "#   President of Russia, and February 23, 2022, the day before Russia’s full-scale invasion of Ukraine \"\n",
    "\n",
    "print(df.shape[0])\n",
    "print(\"First date:\", df.sort_values('dates').iloc[0]['dates'])\n",
    "print(\"Last date:\", df.sort_values('dates').iloc[-1]['dates'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a51bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Data and Estimation Strategy\"\n",
    "\n",
    "# Text in the article: \n",
    "# \" Stories that mentioned Vladimir Putin were identified using keyword search \"\n",
    "\n",
    "# This refers to column 'putin' that has already been defined above.\n",
    "# Code from above is copy-pasted here\n",
    "\n",
    "# Create a column that equals one if the text mentions Putin\n",
    "# df['putin'] = [1 if 'Путин' in text else 0 for text in df['text']]\n",
    "# df['putin'] = df['putin'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Data and Estimation Strategy\"\n",
    "\n",
    "# Text in the article: \n",
    "# \" The stories are all in Russian and, on average, are 235 (SD  = 231) words long \"\n",
    "\n",
    "# Calculate the rounded mean of the 'textlength' column in the DataFrame 'df'\n",
    "rounded_mean = round(df['textlength'].mean())\n",
    "\n",
    "# Calculate the rounded standard deviation of the 'textlength' column in the DataFrame 'df'\n",
    "rounded_std = round(df['textlength'].std())\n",
    "\n",
    "print(f\"The stories are all in Russian and, on average, are {rounded_mean} (SD  = {rounded_std}) words long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Data and Estimation Strategy\"\n",
    "\n",
    "# Text in the article:\n",
    "# \" To verify transcripts’ accuracy, I randomly selected 39 episodes (0.01% of the data) \n",
    "#   from the website and cross-referenced the video content with the text \"\n",
    "\n",
    "random_selection = df.sample(n = 39, random_state = 42)  \n",
    "\n",
    "# procedure: open the website of channel one for the exact date\n",
    "# https://www.1tv.ru/news/issue/year-month-day, watch the episode, compare to the ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Validation of the Classification Results\"\n",
    "\n",
    "# Text in the article: \n",
    "# \" Two annotators, fluent in Russian ....\n",
    "# ...al unlabeled samples from the corpus (n=600)\"\n",
    "\n",
    "# Small dataframes with the validation results are below\n",
    "# They will be used later in the script\n",
    "\n",
    "# The size of the sample to calculate the accuracy of both Rubert-tiny and Newsmap\n",
    "# plus the size of sample used to estimate the precision of Rubert Tiny\n",
    "# plus the soze of sample used to estimate the precision of Newsmap\n",
    "\n",
    "print(sa.shape[0] + pr.shape[0] + pn.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Validation of the Classification Results\"\n",
    "\n",
    "# Text in the article: \n",
    "# \" Each sample was comprised from 100 stories that were randomly selected from the corpus,\n",
    "#   aiming to estimate the accuracy of Rubert-tiny and Newsmap .\"\n",
    "\n",
    "# Sample to calculate accuracy of both Rubert-tiny and Newsmap\n",
    "\n",
    "# Set a random seed to ensure the reproducibility of samples\n",
    "random.seed(42)\n",
    "# Check if the dataset is sorted so that column 'dates' in the main dataframe is in increasing order \n",
    "dates_increasing = df['dates'].is_monotonic_increasing\n",
    "print(\"The dates in increasing order?\", dates_increasing)\n",
    "\n",
    "# Generate 100 random numbers between 0 and 385981\n",
    "random_numbers = random.sample(range(0, df.shape[0]), 100)\n",
    "\n",
    "# Sample to calculate the precision of Rubert-tiny\n",
    "# Select rows from the DataFrame using random numbers and assign to sample_all\n",
    "sample = df.loc[random_numbers]\n",
    "# Keep only the 'dates', 'country', and 'sentiment_labels' columns in sample_all\n",
    "sample = sample[['dates', 'text', 'sentiment_labels', 'country']]\n",
    "\n",
    "# Initialize the 'labels' column to 0\n",
    "sample['labels'] = 0\n",
    "# Set 'labels' to 1 where 'sentiment_labels' is 'positive'\n",
    "sample.loc[sample['sentiment_labels'] == 'positive', 'labels'] = 1\n",
    "# Set 'labels' to -1 where 'sentiment_labels' is 'negative'\n",
    "sample.loc[sample['sentiment_labels'] == 'negative', 'labels'] = -1\n",
    "\n",
    "# The code below can be used to save the sample to .csv\n",
    "# sample.to_csv(\"insert a path here\")\n",
    "# the output file is called sample_accuracy.csv\n",
    "\n",
    "# Display the first few rows of the DataFrame \n",
    "sample.head()\n",
    "\n",
    "# Count of stories \n",
    "print(sample.shape[0])\n",
    "\n",
    "# Check if the text is the same as in validation file\n",
    "print(\"Same as validation file?\", list(sa['text']) == list(sample['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd742c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Validation of the Classification Results\"\n",
    "\n",
    "# Text in the article: \n",
    "#  \" and 300 stories that were randomly\n",
    "#    selected from the subsets of the corpus for each sentiment-class, aiming to\n",
    "#    estimate the precision for “positive,” “negative,” and “neutral” classes\" \n",
    "\n",
    "# Sample used to estimate the precision of Rubert Tiny\n",
    "\n",
    "# Set a random seed to ensure the reproducibility of samples\n",
    "random.seed(42)\n",
    "# Check if the dataset is sorted so that column 'dates' in the main dataframe is in increasing order \n",
    "dates_increasing = df['dates'].is_monotonic_increasing\n",
    "print(\"Are the dates in increasing order?\", dates_increasing)\n",
    "\n",
    "\n",
    "def sample_sentiment(df, sentiment, label, sample_size = 100):\n",
    "    \"\"\"\n",
    "    Samples a given number of entries from the DataFrame for a specific sentiment.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "    sentiment (str): The sentiment label to filter by ('negative', 'neutral', 'positive').\n",
    "    label (int): The label to assign to the sampled entries.\n",
    "    sample_size (int): The number of samples to draw.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A DataFrame with the sampled entries.\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['sentiment_labels'] == sentiment].reset_index(drop=True)\n",
    "    #print(f'{sentiment.capitalize()} stories, count:', filtered_df.shape[0])\n",
    "    random_numbers = random.sample(range(filtered_df.shape[0]), sample_size)\n",
    "    sample_df = filtered_df.loc[random_numbers].copy()\n",
    "    sample_df = sample_df[['dates', 'text', 'sentiment_labels', 'country']]\n",
    "    sample_df['labels'] = label\n",
    "    return sample_df\n",
    "\n",
    "# Sample from each sentiment category\n",
    "sample_negative = sample_sentiment(df, 'negative', -1)\n",
    "sample_neutral = sample_sentiment(df, 'neutral', 0)\n",
    "sample_positive = sample_sentiment(df, 'positive', 1)\n",
    "\n",
    "# Stack the DataFrames vertically\n",
    "sample = pd.concat([sample_negative, sample_neutral, sample_positive], axis = 0).reset_index(drop = True)\n",
    "\n",
    "# The code below can be used to save the sample to .csv\n",
    "# sample.to_csv(\"insert a path here\")\n",
    "# the output file is called precision_rubert.csv\n",
    "# Display the first few rows of the DataFrame\n",
    "sample.head()\n",
    "\n",
    "# Count of stories \n",
    "print(sample.shape[0])\n",
    "\n",
    "# Check if the text is the same as in validation file\n",
    "print(\"Same as validation file?\", list(pr['text']) == list(sample['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcc18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Validation of the Classification Results\"\n",
    "\n",
    "# Text in the article:\n",
    "# \" Based on the labeling, the accuracy score of Rubert-tiny amounted to 81%\" \n",
    "\n",
    "# (Krippendorff's alpha is also reported in A5 in the Appendix)\n",
    "\n",
    "# Calculate Accuracy of Rubert Tiny and Krippendorff's alpha\n",
    "\n",
    "# Check if 'label' matches 'Coder1' and calculate the proportion of matches. Print the result\n",
    "print(\"Accuracy of Rubert-tiny\", (sa['value'] == sa['coder1']).mean())\n",
    "\n",
    "# Labelling data\n",
    "data = {\n",
    "    'coder1': sa['coder1'].astype(int),\n",
    "    'coder2': sa['coder2'].astype(int)\n",
    "}\n",
    "\n",
    "rd = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the reliability data for Krippendorff's alpha\n",
    "reliability_data = [rd['coder1'].tolist(), rd['coder2'].tolist()]\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "alpha = round(krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 2)\n",
    "print(f\"Krippendorff's alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ab13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Validation of the Classification Results\"\n",
    "\n",
    "# Text in the article:\n",
    "# \" while the precision amounted to 81% for “negative,”\n",
    "#  82% for “neutral,” and 95% for “positive” classes%\" \n",
    "\n",
    "# Calculate Precision of Rubert Tiny and Krippendorff's alpha\n",
    "\n",
    "# Calculate precision for each sentiment category\n",
    "for sentiment in ['negative', 'neutral', 'positive']:\n",
    "    subset = pr[pr['sentiment_labels'] == sentiment]\n",
    "    precision = (subset['value'] == subset['coder1']).mean()\n",
    "    print(f\"Precision, {sentiment}: {precision}\")\n",
    "    \n",
    "# Labelling data\n",
    "data = {\n",
    "    'coder1': pr['coder1'].astype(int),\n",
    "    'coder2': pr['coder2'].astype(int)\n",
    "}\n",
    "\n",
    "rd = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the reliability data for Krippendorff's alpha\n",
    "reliability_data = [rd['coder1'].tolist(), rd['coder2'].tolist()]\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "alpha = round(krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 2)\n",
    "print(f\"Krippendorff's alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section \"Validation of the Classification Results\"\n",
    "\n",
    "# Text in the article:\n",
    "# \" The estimate of the accuracy score for Newsmap amounted to 89% \" \n",
    "\n",
    "print(\"Accuracy of Newsmap\", (sa['country'] == sa['c1']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa670cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article:\n",
    "# \" while the precision estimates for the labels “Russia,” “US,” “Ukraine,”\n",
    "#    “United Kingdom” were 100%, 84%, 94%, and 86% respectively\"\n",
    "\n",
    "# Filter data by country-label\n",
    "ru = pn[pn['country'] == 'ru']\n",
    "us = pn[pn['country'] == 'us']\n",
    "ua = pn[pn['country'] == 'ua']\n",
    "gb = pn[pn['country'] == 'gb']\n",
    "\n",
    "# Function to calculate and print precision\n",
    "def print_precision(country_code, df):\n",
    "    precision = (df['value'] == df['coder1']).mean()\n",
    "    print(f\"Precision of Newsmap, {country_code.upper()}: {precision}\")\n",
    "\n",
    "# Print precision for each country-label\n",
    "print_precision('ru', ru)\n",
    "print_precision('us', us)\n",
    "print_precision('ua', ua)\n",
    "print_precision('gb', gb)\n",
    "\n",
    "# Labeling data\n",
    "data = {\n",
    "    'coder1': pn['coder1'].astype(int),\n",
    "    'coder2': pn['coder2'].astype(int)\n",
    "}\n",
    "\n",
    "dat = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the reliability data for Krippendorff's alpha\n",
    "reliability_data = [dat['coder1'].tolist(), dat['coder2'].tolist()]\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "alpha = round(krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 2)\n",
    "print(f\"Krippendorff's alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c34c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1. Corpus from Channel One\n",
    "\n",
    "# Data for Figure 1 \n",
    "\n",
    "# Days within the period under consideration\n",
    "# Create a DataFrame containing all dates from '1999-12-31' to '2022-02-24'\n",
    "all_days = pd.DataFrame(pd.date_range(start = '1999-12-31', end = '2022-02-24'))\n",
    "\n",
    "# Extract only the date portion from the DataFrame and store them in a list\n",
    "all_days = [i.date() for i in all_days[0]]\n",
    "\n",
    "# Create a new DataFrame from the list of dates\n",
    "all_days = pd.DataFrame(all_days)\n",
    "\n",
    "# Rename the column to 'date'\n",
    "all_days = all_days.rename(columns = {0: \"dates\"})\n",
    "\n",
    "# Set the 'date' column as the index of the DataFrame\n",
    "all_days = all_days.set_index(\"dates\")\n",
    "\n",
    "# Episodes per day\n",
    "# Add a new column 'episodes_daily' to the DataFrame 'df' and set all values to 1\n",
    "df['episodes_daily'] = 1  \n",
    "\n",
    "# Group the DataFrame 'df' by the 'date' column, summing up the 'episodes_daily' values for each date\n",
    "# Create a new DataFrame 'counts_all' to store the resulting counts\n",
    "counts_all = pd.DataFrame(df.groupby(by = \"dates\")['episodes_daily'].sum())\n",
    "\n",
    "# Episodes per day about RU -- domestic news\n",
    "# Filter the DataFrame 'df' to include only rows where the 'country' column is 'ru' (Russia)\n",
    "ru = df[df['country'] == 'ru']\n",
    "\n",
    "# Add a new column 'episodes_daily_ru' to the filtered DataFrame 'ru' and set all values to 1\n",
    "ru['episodes_daily_ru'] = 1  \n",
    "\n",
    "# Group the filtered DataFrame 'ru' by the 'date' column, summing up the 'episodes_daily_ru'\n",
    "# values for each date and reate a new DataFrame 'counts_daily_ru' to store the counts\n",
    "counts_daily_ru = pd.DataFrame(ru.groupby(by = \"dates\")['episodes_daily_ru'].sum())\n",
    "\n",
    "# Concatenate the DataFrames 'all_days', 'counts_all', and 'counts_daily_ru'\n",
    "dat = pd.concat([all_days, counts_all, counts_daily_ru], axis = 1)\n",
    "\n",
    "# Fill missing values in the concatenated DataFrame 'dat' with 0\n",
    "dat = dat.fillna(0)\n",
    "\n",
    "# Calculate the share of daily episodes related to Russia ('episodes_daily_ru')\n",
    "# compared to all daily episodes ('episodes_daily')\n",
    "dat['episodes_daily_ru_share'] = dat['episodes_daily_ru'] / dat['episodes_daily']\n",
    "\n",
    "# For the pie chart\n",
    "# Count the number of rows in DataFrame 'df' where the 'country' column is 'ru',\n",
    "# 'us', 'ua', and 'gb' respectively\n",
    "ru = df[df['country'] == 'ru'].shape[0]\n",
    "us = df[df['country'] == 'us'].shape[0]\n",
    "ua = df[df['country'] == 'ua'].shape[0]\n",
    "gb = df[df['country'] ==' gb'].shape[0]\n",
    "\n",
    "# Calculate the count of rows where the 'country' column is other than 'ru',\n",
    "# 'us', 'ua', and 'gb'\n",
    "other = df.shape[0] - (ru + us + ua + gb)\n",
    "\n",
    "# Create lists of countries and their respective episode counts\n",
    "countries = ['ru', 'us', 'ua', 'gb', 'other']\n",
    "episodes = [ru, us, ua, gb, other]\n",
    "\n",
    "# Create a summary DataFrame with 'countries' and 'episodes' columns\n",
    "summary = pd.DataFrame()\n",
    "summary['countries'] = countries\n",
    "summary['episodes'] = episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44229f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drawing Figure 1. Corpus from Channel One\n",
    "\n",
    "# Create a figure with a specific size and white background\n",
    "fig = plt.figure(figsize = (15, 5), facecolor = 'white')\n",
    "\n",
    "# Update font family for the plot\n",
    "plt.rcParams.update({'font.family' : 'Times New Roman'})\n",
    "\n",
    "# Create subplots using grid layout, defining their positions and sizes\n",
    "ax1 = plt.subplot2grid((2, 6), (0, 0), colspan = 5, rowspan = 1)\n",
    "ax2 = plt.subplot2grid((2, 6), (0, 5), colspan = 2, rowspan = 2)\n",
    "ax3 = plt.subplot2grid((2, 6), (1, 0), colspan = 5, rowspan = 1)\n",
    "\n",
    "# Plot the daily counts of news reports in the corpus on ax1\n",
    "# Actual data\n",
    "ax1.plot(dat['episodes_daily'], color = 'black')  \n",
    "# Rolling mean\n",
    "ax1.plot(dat['episodes_daily'].rolling(window = 50).mean(), color = 'lightgray', linewidth = 1)\n",
    "# Remove x-axis ticks\n",
    "ax1.set_xticks([])\n",
    "# Set the title\n",
    "ax1.set_title(\"News reports in the corpus (daily counts)\", fontsize = 17)  \n",
    "\n",
    "# Add vertical dashed lines indicating election dates\n",
    "for i in election_dates:\n",
    "    ax1.axvline(x = i, color = 'dimgray', linestyle = \"dashed\", linewidth = 1)\n",
    "\n",
    "# Set tick parameters for the y-axis\n",
    "ax1.tick_params(axis = 'y', labelsize = 13)  \n",
    "\n",
    "# Create a pie chart on ax2 showing the distribution of episodes by country\n",
    "ax2.pie(summary['episodes'],\n",
    "        colors = ['dimgray', 'darkgrey', 'silver', 'lightgray', 'whitesmoke', 'white'],\n",
    "        labels = ['RU', 'US', 'UA', 'GB', 'Other'],\n",
    "        textprops = {'fontsize': 14},\n",
    "        labeldistance = 1.17,\n",
    "        radius = 1.2)\n",
    "\n",
    "# Set the title for ax2\n",
    "ax2.set_title(\"Country labels \\n in the corpus \\n \", fontsize = 16)\n",
    "\n",
    "# Plot the rolling mean of the share of daily episodes related to Russia on ax3\n",
    "ax3.plot(dat['episodes_daily_ru_share'].rolling(window = 50).mean(), color = 'dimgray', linewidth = 2)\n",
    "\n",
    "# Set major locator and formatter for x-axis, and formatter for y-axis on ax3\n",
    "# Set major locator for months\n",
    "ax3.xaxis.set_major_locator(mdates.MonthLocator(bymonth = (0, 12)))\n",
    "# Set major formatter for y-axis to percent\n",
    "ax3.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "# Customize y-axis tick labels to percent\n",
    "ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, _: '{:.0%}'.format(val)))\n",
    "# Set tick parameters for y-axis\n",
    "ax3.tick_params(axis = 'y', labelsize = 13)\n",
    "# Set tick parameters for x-axis with rotation\n",
    "ax3.tick_params(axis = 'x', rotation = 70, labelsize = 13)  \n",
    "\n",
    "# Add vertical dashed lines indicating election dates on ax3\n",
    "for i in election_dates:\n",
    "    ax3.axvline(x = i, color = 'dimgray', linestyle = \"dashed\", linewidth = 1)\n",
    "\n",
    "# Set the title for ax3\n",
    "ax3.set_title(\"Domestic news reports in the corpus (daily shares)\", fontsize = 17)\n",
    "\n",
    "# Create a new figure with white background for the legend\n",
    "plt.figure(facecolor = 'white')\n",
    "\n",
    "# Plot lines with labels for the legend\n",
    "plt.plot([0, 0], color = 'black', label = \"Episodes, daily\", linewidth = 7)\n",
    "plt.plot([0, 0], color = 'lightgray', label = 'Episodes, daily (a moving average, n = 50)', linewidth = 7)\n",
    "plt.plot([0, 0], color = 'dimgray', label = 'Share of daily newsflow (a moving average, n = 50)', linewidth = 7)\n",
    "plt.plot([0, 0], color = 'black', linestyle = \"dashed\", label='New presidential term', linewidth = 3)\n",
    "\n",
    "# Add legend with specified properties and position\n",
    "plt.legend(prop = {'size': 35}, bbox_to_anchor = (1.1, 1.05))\n",
    "\n",
    "# Show the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 \"Sentiment analysis: classification results\"\n",
    "\n",
    "# Create 'domestic' column\n",
    "df['domestic'] = (df['country'] == 'ru').astype(int)\n",
    "\n",
    "# Get unique years\n",
    "unique_years = df['year'].unique()\n",
    "\n",
    "# Create a loop to assign values to 'year_dummies' column\n",
    "for year in unique_years:\n",
    "    df.loc[df['year'] == year, 'year_dummies'] = f'y{year}'\n",
    "\n",
    "# Table 1, Model 1\n",
    "print ('\\n =============================== Model 1 =============================== \\n')\n",
    "result = sm.ols(formula=\"sentiment_score~putin \", data=df).fit(cov_type='HC3')  \n",
    "print(result.summary())\n",
    "\n",
    "# Table 1, Model 2\n",
    "print ('\\n =============================== Model 2 =============================== \\n')\n",
    "result = sm.ols(formula=\"sentiment_score~putin+domestic \", data=df).fit(cov_type='HC3')  \n",
    "print(result.summary())\n",
    "\n",
    "# Table 1, Model 3\n",
    "print ('\\n =============================== Model 3 =============================== \\n')\n",
    "result = sm.ols(formula=\"sentiment_score~putin+domestic+year_dummies\", data=df).fit(cov_type='HC3')  \n",
    "print(result.summary())\n",
    "\n",
    "# Table 1, Model 4\n",
    "print ('\\n =============================== Model 4 =============================== \\n')\n",
    "result = sm.logit(formula=\"putin ~ sentiment_labels\", data=df).fit()\n",
    "print(result.summary())\n",
    "\n",
    "# Table 1, Model 5\n",
    "print ('\\n =============================== Model 5 =============================== \\n')\n",
    "result = sm.logit(formula=\"putin ~ sentiment_labels+domestic+year_dummies\", data=df).fit()\n",
    "print(result.summary())\n",
    "\n",
    "# Table 1, Model 6\n",
    "print ('\\n =============================== Model 6 =============================== \\n')\n",
    "df1 = df[df['sentiment_labels']!='neutral']\n",
    "result = sm.logit(formula=\"putin ~ sentiment_labels+ domestic + year_dummies\", data=df1).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26271e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for figures 2, 3, 4 and 5 and Table 2\n",
    "\n",
    "# Days within the period under consideration\n",
    "# Generate a DataFrame containing all dates from '1999-12-31' to '2022-02-24'\n",
    "all_days = pd.DataFrame(pd.date_range(start = '1999-12-31', end = '2022-02-24'))\n",
    "\n",
    "# Extract date values from the DataFrame and create a new DataFrame\n",
    "all_days = [i.date() for i in all_days[0]]\n",
    "all_days = pd.DataFrame(all_days)\n",
    "\n",
    "# Rename the column to \"dates\" and set it as the index of the DataFrame\n",
    "all_days = all_days.rename(columns={0: \"dates\"})\n",
    "all_days = all_days.set_index(\"dates\")\n",
    "\n",
    "# Episodes per day\n",
    "df['episodes_daily'] = 1\n",
    "counts_all = pd.DataFrame(df.groupby(by = \"dates\")['episodes_daily'].sum())\n",
    "\n",
    "# Counts - mentions of Putin\n",
    "putin = pd.DataFrame(df.groupby(by = \"dates\")['putin'].sum())\n",
    "putin.rename(columns = {'putin' : \"putin_episodes_daily\"},\n",
    "             inplace = True)\n",
    "# Foreign\n",
    "foreign = df[df['country'] != 'ru']\n",
    "foreign = pd.DataFrame(foreign.groupby(by = \"dates\")['episodes_daily'].sum())\n",
    "foreign.rename(columns = {'episodes_daily' : \"foreign_episodes_daily\"},\n",
    "               inplace = True)\n",
    "# Domestic\n",
    "domestic = df[df['country'] == 'ru']\n",
    "domestic = pd.DataFrame(domestic.groupby(by = \"dates\")['episodes_daily'].sum())\n",
    "domestic.rename(columns = {'episodes_daily' : \"domestic_episodes_daily\"},\n",
    "                inplace = True)\n",
    "\n",
    "# Foreign and Putin\n",
    "foreign_putin = df[df['country'] != 'ru']\n",
    "foreign_putin = pd.DataFrame(foreign_putin.groupby(by = \"dates\")['putin'].sum())\n",
    "foreign_putin.rename(columns = {'putin' : \"foreign_putin_daily\"},\n",
    "                     inplace = True)\n",
    "# Domestic and Putin\n",
    "domestic_putin = df[df['country'] == 'ru']\n",
    "domestic_putin = pd.DataFrame(domestic_putin.groupby(by = \"dates\")['putin'].sum())\n",
    "domestic_putin.rename(columns = {'putin' : \"domestic_putin_daily\"},\n",
    "                      inplace = True)\n",
    "\n",
    "# This dataframe will be used in the tests and figures below\n",
    "dat = pd.concat([all_days,\n",
    "                 counts_all,\n",
    "                 putin,\n",
    "                 foreign,\n",
    "                 domestic,\n",
    "                 foreign_putin,\n",
    "                 domestic_putin],\n",
    "                axis = 1)\n",
    "\n",
    "dat['putin_daily_share'] = dat['putin_episodes_daily'] / dat['episodes_daily']\n",
    "dat['putin_foreign_share'] = dat['foreign_putin_daily'] / dat['foreign_episodes_daily']\n",
    "dat['putin_domestic_share'] = dat['domestic_putin_daily'] / dat['domestic_episodes_daily']\n",
    "dat['share_of_foreign_in_putin'] =  dat['foreign_putin_daily'] / dat['putin_episodes_daily']\n",
    "dat = dat.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07627163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2. Sentiment Estimates\n",
    "\n",
    "# Extract and set the 'dates' and 'sentiment_score' columns from DataFrame df \n",
    "# and set 'dates' as index for dat1\n",
    "dat1 = df[['dates', 'sentiment_score']]\n",
    "dat1 = dat1.set_index('dates')\n",
    "\n",
    "# Filter DataFrame df for rows where 'putin' equals 1,\n",
    "# extract 'dates' and 'sentiment_score' columns, and set 'dates' as index for dat2\n",
    "dat2 = df[df['putin'] == 1]\n",
    "dat2 = dat2[['dates', 'sentiment_score']]\n",
    "dat2 = dat2.set_index('dates')\n",
    "\n",
    "# Create subplots for two plots, set figure size and background color\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 1, figsize = (15, 6), facecolor = 'white')\n",
    "\n",
    "# Plot rolling mean of 'sentiment_score' for dat1 and dat2 on ax[0] \n",
    "ax[0].plot(dat1['sentiment_score'].rolling(window = 50).mean(), color = 'black', linewidth = 2)\n",
    "ax[0].plot(dat2['sentiment_score'].rolling(window = 50).mean(), color = 'darkgrey', linewidth = 2)\n",
    "\n",
    "# Format x-axis ticks and labels for ax[0]\n",
    "ax[0].xaxis.set_major_locator(mdates.MonthLocator(bymonth = (0, 12)))\n",
    "ax[0].tick_params(axis = 'x', rotation = 45, labelsize = 16)\n",
    "ax[0].tick_params(axis = 'y', labelsize = 16)\n",
    "\n",
    "# Set title and ylabel for ax[0]\n",
    "ax[0].set_title('Sentiment estimates of news stories (Rubert-tiny)', fontsize = 20)\n",
    "ax[0].set_ylabel('A moving average\\n (n=50)', fontsize = 16)\n",
    "ax[0].set_xticklabels([])  # Remove x-axis tick labels\n",
    "ax[0].yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.2f}'))  # Format y-axis labels\n",
    "\n",
    "# Plot rolling mean of 'sentiment_score' \n",
    "ax[1].plot(dat1['sentiment_score'].rolling(window = 1000).mean(), color = 'black', linewidth = 2)\n",
    "ax[1].plot(dat2['sentiment_score'].rolling(window = 1000).mean(), color = 'darkgrey', linewidth = 2)\n",
    "\n",
    "# Format x-axis ticks and labels for ax[1]\n",
    "ax[1].xaxis.set_major_locator(mdates.MonthLocator(bymonth = (0, 12)))\n",
    "ax[1].tick_params(axis = 'x', rotation = 45, labelsize = 16)\n",
    "ax[1].tick_params(axis = 'y', labelsize = 16)\n",
    "\n",
    "# Set ylabel for ax[1]\n",
    "ax[1].set_ylabel('A moving average\\n (n=1,000)', fontsize = 16)\n",
    "\n",
    "# Add vertical dashed lines for election dates on ax[1]\n",
    "for i in election_dates:\n",
    "    ax[1].axvline(x = i, color = 'black', linestyle = \"dashed\", linewidth = 1)\n",
    "# Format y-axis labels\n",
    "ax[1].yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.2f}'))  \n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend for Figure 2\n",
    "\n",
    "# Create a new figure with white background for the legend\n",
    "plt.figure(facecolor = 'white')\n",
    "\n",
    "# Plot lines with specific colors and labels for the legend\n",
    "plt.plot([0, 0], color = 'black', label = \"All stories\", linewidth = 2)\n",
    "plt.plot([0, 0], color = 'darkgrey', label = \"Stories that involve Putin\", linewidth = 2)\n",
    "plt.plot([0, 0], color = 'black', linestyle = \"dashed\", label = 'New presidential term', linewidth = 2)\n",
    "\n",
    "# Add legend with specified properties and position\n",
    "plt.legend(prop={'size' : 15}, bbox_to_anchor=(2, 2))\n",
    "\n",
    "# Adjust layout and display the legend\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram at the bottom of Figure 2\n",
    "\n",
    "# Filter DataFrame df for rows where 'putin' equals 1\n",
    "df1 = df[df['putin'] == 1]\n",
    "\n",
    "# Numbers to be used in the title of the histogram in Figure 2\n",
    "\n",
    "print(df.shape[0])\n",
    "print(df1.shape[0]) \n",
    "\n",
    "# Create a figure with 1 row and 2 columns for the histograms\n",
    "fig, axs = plt.subplots(1, 2, figsize = (7, 2))\n",
    "\n",
    "# Plot histograms for 'sentiment_score' in both DataFrames\n",
    "axs[0].hist(df['sentiment_score'], bins = 100, color = 'black', label = 'Histogram 1')\n",
    "axs[1].hist(df1['sentiment_score'], bins = 100, color = 'gray', label = 'Histogram 2')\n",
    "\n",
    "# Set titles and labels for each subplot\n",
    "axs[0].set_title('All stories (n=385,981)')\n",
    "axs[1].set_title('Stories that involve Vladimir Putin (n=45,769)')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "# Hide y-axis labels for the second histogram\n",
    "axs[1].tick_params(axis = 'y', labelleft = False) \n",
    "axs[0].get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))  \n",
    "axs[0].set_xlabel('Sentiment score')\n",
    "axs[1].set_xlabel('Sentiment score')\n",
    "\n",
    "# Adjust layout and display the histograms\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article:\n",
    "\n",
    "# \" Overall, 23% of the stories in the corpus were labeled as negative, \n",
    "#   52% as neutral, and 25% as positive. The related shares for the stories \n",
    "#   that involve Putin are 9%, 56%, and 34%. \"\n",
    "\n",
    "print('Overall: \\n')\n",
    "print('Negative:', round(df[df['sentiment_labels'] == 'negative'].shape[0] / df.shape[0],2))\n",
    "print('Neutral', round(df[df['sentiment_labels'] == 'neutral'].shape[0] / df.shape[0],2))\n",
    "print('Positive', round(df[df['sentiment_labels']== 'positive'].shape[0] / df.shape[0],2), '\\n')\n",
    "\n",
    "print('Involve Putin:')\n",
    "\n",
    "dfp = df[df['putin']==1] # subset to only stories that involve 'Putin'\n",
    "print('Negative:', round(dfp[dfp['sentiment_labels'] == 'negative'].shape[0] / dfp.shape[0],2))\n",
    "print('Neutral', round(dfp[dfp['sentiment_labels'] == 'neutral'].shape[0] / dfp.shape[0],2))\n",
    "print('Positive', round(dfp[dfp['sentiment_labels'] == 'positive'].shape[0] / dfp.shape[0],2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb09e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3. The daily share of news reports that mention Vladimir Putin\n",
    "\n",
    "# Create a subplot with specific size and background color\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15, 2), facecolor = 'white')\n",
    "\n",
    "# Add vertical dashed lines for election dates\n",
    "for i in election_dates:\n",
    "    ax.axvline(x = i, color = 'black', linestyle = \"dashed\", linewidth = 1)\n",
    "\n",
    "# Set major formatters and locators for both axes and adjust tick parameters\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth = (0, 12)))\n",
    "ax.tick_params(axis = 'x', rotation = 45, labelsize = 16)\n",
    "ax.tick_params(axis = 'y', labelsize = 13)\n",
    "\n",
    "# Set title for the plot\n",
    "ax.set_title(\"The daily share of news reports that mention Vladimir Putin\", fontsize = 17)\n",
    "\n",
    "# Set additional y-axis formatter, adjust tick parameters, set ylabel and plot data\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "ax.set_ylabel('A moving average \\n (n=50)', fontsize = 16)\n",
    "ax.plot(dat['putin_daily_share'].rolling(window = 50).mean(), color = 'black', linewidth = 2)\n",
    "\n",
    "# Annotate the plot with a text and an annotation box\n",
    "plt.annotate(\"Dmitry Medvedev \\n serves as the president,\\n May 2008–May 2012\",\n",
    "             xy = (dat.index[5050], 0), xytext = (dat.index[3200], 0.18),\n",
    "             size = 14, bbox = dict(boxstyle = \"round\", fc = 'white', color = 'white'))\n",
    "\n",
    "# Add text with annotation box\n",
    "props = dict(facecolor = 'white', edgecolor = 'white', alpha = 0.8)\n",
    "ax.text(0.4, 0.7, 'Dmitry Medvedev \\n serves as the president, \\n May 2008—May 2012',\n",
    "        ha = 'left', va = 'center', transform = ax.transAxes, fontsize = 14, bbox = props)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2. Daily references to Putin\n",
    "\n",
    "# Assign the index values of the DataFrame to the 'dates' column\n",
    "dat['dates'] = dat.index.values\n",
    "\n",
    "# Initialize the 'term' column with a value of 1\n",
    "dat['term'] = 1\n",
    "\n",
    "# Update 'term' to 2 where the 'date' is greater than a specified value (el2)\n",
    "dat.loc[dat['dates'] > el2, 'term'] = 2\n",
    "\n",
    "# Update 'term' to 'Medvedev' where the 'date' is greater than a specified value (el3)\n",
    "dat.loc[dat['dates'] > el3, 'term'] = 'Medvedev'\n",
    "\n",
    "# Updating 'term' to 3 where the 'date' is greater than a specified value (el4)\n",
    "dat.loc[dat['dates'] > el4, 'term'] = 3\n",
    "\n",
    "# Updating 'term' to 4 where the 'date' is greater than a specified value (el5)\n",
    "dat.loc[dat['dates'] > el5, 'term'] = 4\n",
    "\n",
    "# Model 1\n",
    "print ('\\n =============================== Model 1 =============================== \\n')\n",
    "result = sm.ols(formula = \"putin_daily_share ~ term\", data = dat).fit(cov_type = 'HC3') \n",
    "print(result.params)\n",
    "print(result.summary())\n",
    "\n",
    "# Model 2\n",
    "print ('\\n =============================== Model 2 =============================== \\n')\n",
    "result = sm.ols(formula=\"putin_daily_share ~ term + foreign_episodes_daily\", data = dat).fit(cov_type = 'HC3') \n",
    "print(result.params)\n",
    "print(result.summary())\n",
    "\n",
    "# ADF test\n",
    "print ('\\n =============================== ADF test =============================== \\n')\n",
    "result = adfuller(dat['putin_daily_share'])\n",
    "adf_statistic = result[0]\n",
    "p_value = result[1]\n",
    "critical_values = result[4]\n",
    "\n",
    "# Displaying the results\n",
    "print(f'ADF Statistic: {adf_statistic}')\n",
    "print(f'p-value: {p_value}')\n",
    "print('Critical Values:')\n",
    "for key, value in critical_values.items():\n",
    "    print(f'   {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434515fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article (subsection 'H2 (Frequency)'):\n",
    "\n",
    "# \" On average, Vladimir Putin was mentioned in 13% of the news episodes during his\n",
    "#   first presidential term (2000–2004),\n",
    "#   10% during the second (2004–2008),\n",
    "#   6% during his premiership (2008–2012),\n",
    "#   13% during the third (2012–2018)\n",
    "#   and in 20% during the period between\n",
    "#   the beginning of his fourth presidential term (2018) and February 23, 2022 \"\n",
    "\n",
    "dfp = df[df['putin']==1] # only stories that mention Putin\n",
    "\n",
    "def proportion(term):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of rows for a given term in dfp (only stories that mention Putin)\n",
    "    relative to df (all stories).\n",
    "    \"\"\"\n",
    "    # Calculate the number of rows in dfp for the given term\n",
    "    dfp_term_count = dfp[dfp['term'] == term].shape[0]\n",
    "    \n",
    "    # Calculate the number of rows in df for the given term\n",
    "    df_term_count = df[df['term'] == term].shape[0]\n",
    "    \n",
    "    # Calculate the proportion and round it to 3 decimal places\n",
    "    proportion = round(dfp_term_count / df_term_count, 2)\n",
    "    \n",
    "    return proportion\n",
    "\n",
    "print('First presidential term:', proportion(1))\n",
    "print('Second presidential term:', proportion(2))\n",
    "print('Premiership:', proportion('Medvedev'))\n",
    "print('Third presidential term:', proportion(1))\n",
    "print('The period between the beginning of his fourth presidential term (2018) and February 23, 2022:', proportion(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article (subsection 'H2 (Frequency)'):\n",
    "# Footnote: \n",
    "\n",
    "# \" The stories mentioning Putin are, on average, 50.31% longer than all the other stories \"\n",
    "print('The difference is',\n",
    "      round((dfp['textlength'].mean()- df['textlength'].mean())/df['textlength'].mean() * 100,2),\n",
    "      '%\\n')\n",
    "\n",
    "# \"(the difference is statistically significant at 0.01 level) \"\n",
    "result = sm.ols(formula = \"textlength ~ putin\", data = df).fit(cov_type='HC3') \n",
    "print(result.params)\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ce08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article (subsection H3 (Country-topics):\n",
    "\n",
    "# \" The ruler was covered by 3% of the news about foreign affairs and events\n",
    "#   abroad in 2012, 5% in 2013, 8% in 2014, 9% in 2015, 10% in 2016,\n",
    "#   12% in 2017, 14% in 2018, 2019, and 2020, 18% in 2021, and 24% in the first two months of 2022. \"\n",
    "\n",
    "def share(year):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of foreign stories that involve Putin in a given year\n",
    "    \"\"\"\n",
    "    # Count of foreign stories that involve Putin in a given year\n",
    "    fp = df[(df['year'] == year) & (df['country'] != 'ru') & (df['putin'] == 1)].shape[0]\n",
    "    \n",
    "    # Count of foreign stories in a given year\n",
    "    f = df[(df['year'] == year) & (df['country'] != 'ru')].shape[0]\n",
    "    \n",
    "    share = round(fp / f * 100,)\n",
    "   \n",
    "    return share\n",
    "\n",
    "# Print the shares for each year from 2012 to 2022\n",
    "for year in list(range(2012, 2023)):\n",
    "    print(year, ':', share(year), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803bae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot with specific size and background color for Figure 4\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15, 3), facecolor = 'white')\n",
    "\n",
    "# Plot rolling averages of shares of domestic and foreign news reports mentioning Putin\n",
    "ax.plot(dat['putin_domestic_share'].rolling(window = 50).mean(), color = 'black', linewidth = 2)\n",
    "ax.plot(dat['putin_foreign_share'].rolling(window = 50).mean(), color = 'gray', linewidth = 2)\n",
    "\n",
    "# Add vertical dashed lines for election dates\n",
    "for i in election_dates:\n",
    "    ax.axvline(x = i, color = 'black', linestyle = \"dashed\", linewidth = 1)\n",
    "\n",
    "# Set major formatters, locators, and adjust tick parameters for both axes\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth = (0, 12)))\n",
    "ax.tick_params(axis = 'x', rotation = 45, labelsize = 16)\n",
    "ax.tick_params(axis = 'y', labelsize = 13)\n",
    "\n",
    "# Set additional y-axis formatter and adjust tick parameters\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "# Set title for the plot and add annotation\n",
    "ax.set_title('Daily shares of all domestic and foreign news stories that mention Vladimir Putin', fontsize = 18)\n",
    "ax.annotate(\"Dmitry Medvedev \\n serves as the president,\\n May 2008–May 2012\",\n",
    "             xy = (dat.index[5050], 0), xytext = (dat.index[3200], 0.18),\n",
    "             size = 14, bbox = dict(boxstyle = \"round\", fc = 'white', color = 'white'))\n",
    "\n",
    "# Set ylabel and adjust layout\n",
    "ax.set_ylabel('A moving average\\n (n=50)', fontsize = 16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99453c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend for Figure 4\n",
    "\n",
    "# Create a new figure with white background for the legend\n",
    "plt.figure(facecolor = 'white')\n",
    "\n",
    "# Plot lines with specific colors and labels for the legend\n",
    "plt.plot([0, 0], color = 'black', label = \"Domestic\", linewidth = 7)\n",
    "plt.plot([0, 0], color = 'gray', label = \"Foreign\", linewidth = 7)\n",
    "\n",
    "# Add legend with specified properties and position\n",
    "plt.legend(prop = {'size': 35}, bbox_to_anchor = (2, 2))\n",
    "\n",
    "# Adjust layout and display the legend\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: The share of foreign news in all the stories that mention Vladimir Putin\n",
    "\n",
    "# Create a subplot for Figure 5 with specified size and background color\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15, 3), facecolor = 'white')\n",
    "\n",
    "# Plot rolling average of share of foreign news in stories mentioning Putin\n",
    "ax.plot(dat['share_of_foreign_in_putin'].rolling(window = 50).mean(), color = 'black', linewidth = 2)\n",
    "\n",
    "# Add annotation for the period when Dmitry Medvedev served as president\n",
    "plt.annotate(\"Dmitry Medvedev \\n serves as the president,\\n May 2008–May 2012\",\n",
    "             xy = (dat.index[5000], 0.45), xytext = (dat.index[3200], 0.38),\n",
    "             size = 14, bbox = dict(boxstyle = \"round\", fc = 'white', color = 'white'))\n",
    "\n",
    "# Add vertical dashed lines for election dates\n",
    "for i in election_dates:\n",
    "    ax.axvline(x = i, color = 'black', linestyle = \"dashed\", linewidth = 1)\n",
    "\n",
    "# Set major formatters, locators, and adjust tick parameters for both axes\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth = (0, 12)))\n",
    "ax.tick_params(axis = 'x', rotation = 45, labelsize = 16)\n",
    "ax.tick_params(axis = 'y', labelsize = 13)\n",
    "\n",
    "# Set additional y-axis formatter and adjust tick parameters\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(2))\n",
    "ax.tick_params(axis = 'x', rotation = 45, labelsize = 16)\n",
    "ax.tick_params(axis = 'y', labelsize = 16)\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "# Set title, ylabel, and display the plot\n",
    "ax.set_title('The share of foreign news in all the stories that mention Vladimir Putin', fontsize = 20)\n",
    "ax.set_ylabel('A moving average\\n (n=50)', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60be8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article (subsection H3 (Country-topics):\n",
    "\n",
    "# \"However, importantly, every year from 2000 to the first two months of 2022,\n",
    "#  Vladimir Putin has been more frequently mentioned in reports that cover domestic\n",
    "#  events than in stories about foreign affairs and news originating abroad.\n",
    "\n",
    "\n",
    "def more_frequently (year):\n",
    "    \"\"\"\n",
    "    Check if Putin is more frequently mentioned in reports that cover domestic events\n",
    "    \"\"\"\n",
    "    # Count of foreign stories that involve Putin in a given year\n",
    "    fp = df[(df['year'] == year) & (df['country'] != 'ru') & (df['putin'] == 1)].shape[0]\n",
    "    \n",
    "    # Count of domestic stories that involve Putin in a given year\n",
    "    dp = df[(df['year'] == year) & (df['country'] == 'ru') & (df['putin'] == 1)].shape[0]\n",
    "   \n",
    "    return dp > fp\n",
    "\n",
    "# Check if Putin is mentioned more frequently in reports that cover domestic events\n",
    "for year in list(range(2000, 2023)):\n",
    "    print(year, ':', more_frequently(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979bd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article (subsection H3 (Country-topics):\n",
    "\n",
    "# \" On average, news about foreign affairs and events amounted to 28% of all \n",
    "#   reports that covered the ruler during his acting presidency and the first\n",
    "#   term in power (2000–2004), 24% during his second presidential term (2004–2008),\n",
    "#   13% during his premiership (2008–2012),\n",
    "#   35% during his third presidential term (2012–2018),\n",
    "#   and 27% during the period between the beginning of\n",
    "#   his fourth presidential term (2018)\n",
    "#   and February 23, 2022. \" \n",
    "\n",
    "\n",
    "def prop_foreign (term):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of foreign news in all reports that covered Putin\n",
    "    \"\"\"\n",
    "    # Stories that mentioned Putin in a given term\n",
    "    p = df[(df['term'] == term) & (df['putin'] == 1)].shape[0]\n",
    "    # Foreign stories that mentioned Putin in a given term\n",
    "    fp = df[(df['term'] == term) & (df['country'] != 'ru') & (df['putin'] == 1)].shape[0]\n",
    "    prop = round(fp/p*100, )\n",
    "    \n",
    "    return prop\n",
    "\n",
    "for term in list(set(df['term'])):\n",
    "    print('Term', term, prop_foreign(term), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5f773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text in the article (subsection H3 (Country-topics):\n",
    "# \" The coverage was primarily focused on Ukraine and the United States. \"\n",
    "\n",
    "# Find most-popular country-topics\n",
    "p = df[(df['country'] != 'ru') & (df['putin'] == 1)]['country']\n",
    "# Select the top 5\n",
    "print(p.value_counts().sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Figrue 6\n",
    "\n",
    "# Mapping the county-labeles from Newsmap to country-labeles from Plotly\n",
    "# Create a list with the labels from Newsmap\n",
    "newsmap_code = ['ae', 'af', 'am', 'ar', 'at', 'au', 'az', 'be', 'bg', 'br', 'by', 'ca',\n",
    "                'ch', 'cn', 'co', 'cu', 'cy', 'cz', 'de', 'dz', 'ec', 'eg', 'es', 'fi',\n",
    "                'fr', 'gb', 'ge', 'gr', 'hu', 'id', 'il', 'iq', 'ir', 'it', 'jp', 'kg',\n",
    "                'kp', 'kz', 'lt', 'lv', 'md', 'ml', 'mt', 'mx', 'ng', 'nl', 'nz', 'ph',\n",
    "                'pk', 'pl', 'qa', 'rs', 'sa', 'sg', 'sk', 'ss', 'sy', 'tj', 'tm', 'tr',\n",
    "                'ua', 'us', 'uz', 've', 'vn', 'za', 'al', 'ba', 'bh', 'bo', 'cl', 'ee',\n",
    "                'gn', 'gq', 'hr', 'in', 'is', 'jo', 'lb', 'lu', 'ly', 'ma', 'mc', 'me',\n",
    "                'mn', 'my', 'mz', 'no', 'np', 'pt', 'py', 'ro', 'se', 'si', 'sn', 'tg',\n",
    "                'th', 'ug', 'uy']\n",
    "# Create a list with analogous labels from Plotly\n",
    "plotly_code = ['ARE', 'AFG', 'ARM', 'ARG', 'AUT', 'AUS', 'AZE', 'BEL', 'BGR', 'BRA',\n",
    "               'BLR', 'CAN', 'CHE', 'CHN', 'COL', 'CUB', 'CYP', 'CZE', 'DEU', 'DZA',\n",
    "               'ECU', 'EGY', 'ESP', 'FIN', 'FRA', 'GBR', 'GEO', 'GRC', 'HUN', 'IDN',\n",
    "               'ISR', 'IRQ', 'IRN', 'ITA', 'JPN', 'KGZ', 'KOR', 'KAZ', 'LTU', 'LVA',\n",
    "               'MDA', 'MLI', 'MLT', 'MEX', 'NGA', 'NLD', 'NZL', 'PHL', 'PAK', 'POL',\n",
    "               'QAT', 'SRB', 'SAU', 'SGP', 'SVK', 'SSD', 'SYR', 'TJK', 'TKM', 'TUR',\n",
    "               'UKR', 'USA', 'UZB', 'VEN', 'VNM', 'ZAF', 'ALB', 'BIH', 'BHR', 'BOL',\n",
    "               'CHL', 'EST', 'GIN', 'GNQ', 'HRV', 'IND', 'ISL', 'JOR', 'LBN', 'LUX',\n",
    "               'LBY', 'MAR', 'MCO', 'MNE', 'MNG', 'MYS', 'MOZ', 'NOR', 'NPL', 'PRT',\n",
    "               'PRY', 'ROU', 'SEN', 'SVN', 'SEN', 'TGO', 'THA', 'UGA', 'URY']\n",
    "\n",
    "# Filter dataframe to select rows where the country is not 'ru' and 'putin' column is 1\n",
    "df1 = df[df['country'] != 'ru']\n",
    "df1 = df1[df1['putin'] == 1]\n",
    "\n",
    "# Initialize an empty list to store counts\n",
    "cnt = []\n",
    "\n",
    "# Iterate over newsmap_code\n",
    "for i in newsmap_code:\n",
    "    # Subset df1 for each country code and count the number of rows\n",
    "    df2 = df1[df1['country'] == i]\n",
    "    cnt.append(df2.shape[0])\n",
    "\n",
    "# Create a dictionary with data for the plotly map\n",
    "data = {'newsmap_code': newsmap_code,\n",
    "        'plotly_code': plotly_code,\n",
    "        'cnt': cnt}\n",
    "\n",
    "# Create a DataFrame using the dictionary\n",
    "plotlymap = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N of episodes - for the legend\n",
    "print(df1.shape[0])\n",
    "\n",
    "# Define a grey colorscale for the map\n",
    "greys = [\n",
    "    [0, '#f7f7f7'], [0.1, '#eeeeee'], [0.2, '#e5e5e5'], [0.3, '#d9d9d9'],\n",
    "    [0.4, '#cccccc'], [0.5, '#b0b0b0'], [0.6, '#999999'], [0.7, '#7d7d7d'],\n",
    "    [0.8, '#666666'], [0.9, '#4d4d4d'], [1.0, '#333333']\n",
    "]\n",
    "\n",
    "# Create a choropleth map using Plotly\n",
    "fig = go.Figure(data = go.Choropleth(\n",
    "    locations = plotlymap['plotly_code'],\n",
    "    z = plotlymap['cnt'],\n",
    "    colorscale = greys,  # Use the grey colorscale\n",
    "    autocolorscale = False,\n",
    "    marker_line_color = 'black',\n",
    "    marker_line_width = 0.5,\n",
    "    colorbar_tickprefix = '',\n",
    "    colorbar_title = 'Episodes (n = 12,786)',\n",
    "    colorbar = dict(\n",
    "        tickformat = ',',  # Adds commas as thousand separators\n",
    "    )\n",
    "))\n",
    "\n",
    "# Customize layout settings for the map\n",
    "fig.update_layout(\n",
    "    font_family = \"Times New Roman\",\n",
    "    font_color = \"black\",\n",
    "    title_font_family = \"Times New Roman\",\n",
    "    title_font_color = \"black\",\n",
    "    legend_title_font_color = \"green\",\n",
    "    title = {\n",
    "        'text': \"News reports about foreign affairs and foreign events that mention Vladimir Putin\",\n",
    "        'x': 0.5,  # Center the title horizontally\n",
    "        'xanchor': 'center'  # Center the title horizontally\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the choropleth map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A1. Example of a news transcript\n",
    "\n",
    "# Create a datetime object for comparison\n",
    "print(list(df[df['dates'] == date(2019, 3, 12)]['text'])[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A3. Labelled news reports: positive, neutral, negative\n",
    "\n",
    "x = df[(df['dates'] == date(2019, 3, 13)) & (df['sentiment_labels'] == 'positive')]\n",
    "print('Positive\\n', list(x['text'])[7])\n",
    "\n",
    "x = df[(df['dates'] == date(2019, 3, 12)) & (df['sentiment_labels'] == 'neutral')]\n",
    "print('Neutral\\n', list(x['text'])[3])\n",
    "\n",
    "x = df[(df['dates'] == date(2019, 1, 10)) & (df['sentiment_labels'] == 'negative')]\n",
    "print('Negative\\n', list(x['text'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A4. Newsmap\n",
    "\n",
    "# Text in the Appendix: \n",
    "# \" Based on the classification results, the most popular countries of news event\n",
    "#   origin in the dataset are Russia (55%), the United States (10%), Ukraine (7%),\n",
    "#   France (2%), the United Kingdom (2%), Germany (2%), Syria (2%), Georgia (1%),\n",
    "#   Japan (1%), and Turkey (1%) \"\n",
    "\n",
    "# Get the top 9 countries by count and calculate their share\n",
    "top = df['country'].value_counts().nlargest(10).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "top.columns = ['country', 'count']\n",
    "\n",
    "# Calculate the share\n",
    "top['share'] = round(top['count'] / df.shape[0], 2)\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5. Human-based validation\n",
    "\n",
    "# Krippendorff's alpha for the accuracy of Rubert Tiny \n",
    "\n",
    "def label_coder_data(df):\n",
    "    \"\"\"\n",
    "    Create a new DataFrame with labeled coder data.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The original DataFrame containing the coder data.\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame with labeled coder data.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'coder1': df['coder1'].astype(int),\n",
    "        'coder2': df['coder2'].astype(int)\n",
    "    }\n",
    "    labeled_df = pd.DataFrame(data)\n",
    "    return labeled_df\n",
    "\n",
    "# Label the sample for accuracy\n",
    "rd = label_coder_data(sa)\n",
    "# Prepare the reliability data for Krippendorff's alpha\n",
    "reliability_data = [rd['coder1'].tolist(), rd['coder2'].tolist()]\n",
    "# Calculate Krippendorff's alpha\n",
    "alpha = round(krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 2)\n",
    "print(f\"Krippendorff's alpha for the accuracy: {alpha}\")\n",
    "\n",
    "# Krippendorff's alpha for the precision of Rubert Tiny \n",
    "# Label the sample for the precision of Rubert Tiny \n",
    "rd = label_coder_data(pr)\n",
    "# Prepare the reliability data for Krippendorff's alpha\n",
    "reliability_data = [rd['coder1'].tolist(), rd['coder2'].tolist()]\n",
    "\n",
    "# Calculate Krippendorff's alpha for precision of Rubert Tiny\n",
    "alpha = round(krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 2)\n",
    "print(f\"Krippendorff's alpha for precision of Rubert Tiny : {alpha}\")\n",
    "\n",
    "# Calculate Krippendorff's alpha for the Precision of Newsmap\n",
    "# Label the sample for for the Precision of Newsmap\n",
    "rd = label_coder_data(pn)\n",
    "# Prepare the reliability data for Krippendorff's alpha\n",
    "reliability_data = [rd['coder1'].tolist(), rd['coder2'].tolist()]\n",
    "\n",
    "# Calculate Krippendorff's alpha for the Precision of Newsmap\n",
    "alpha = round(krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 2)\n",
    "print(f\"Krippendorff's alpha for precision Newsmap: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A6. Most frequent words in the sentences that refer to Vladimir Putin\n",
    "\n",
    "# Filter dataframe for rows where 'putin' is 1 and select relevant columns\n",
    "df1 = df[df['putin'] == 1][['dates', 'text', 'putin']]\n",
    "\n",
    "# Extract sentences containing 'Путин'\n",
    "sentences = [''.join([sentence + '.' for sentence in text.split('.') if 'Путин' in sentence]) for text in df1['text']]\n",
    "\n",
    "# Split sentences into words\n",
    "allwords = list(itertools.chain.from_iterable([sentence.split() for sentence in sentences]))\n",
    "\n",
    "# Lowercase and remove punctuation\n",
    "cleaned_words = [word.lower().strip('.,:;«»\"') for word in allwords]\n",
    "\n",
    "# Remove stopwords and specified words\n",
    "stopwords = set(stopwords)\n",
    "# Additional context-specific stopwords and declenatinos of name 'Vladimir Putin'\n",
    "todrop = ['', '\"мы', '-', '1', '10', '2', '20', 'в', 'владимир', 'владимира',\n",
    "          'владимиром', 'владимиру', 'вместе', 'вообще', 'время', 'всe', 'все,',\n",
    "          'всего,', 'всем', 'всё', 'второй', 'выпуске', 'год', 'года', 'году',\n",
    "          'государства', 'двух', 'действительно', 'день', 'дня', 'другие',\n",
    "          'других', 'ещe', 'ещё', 'затем', 'и', 'и,', 'из-за', 'именно',\n",
    "          'какие', 'канал', 'касается', 'конечно,', 'которая', 'которое',\n",
    "          'которой', 'которые', 'который', 'которых', 'кремле', 'кремля',\n",
    "          'кроме', 'лет', 'лишь', 'медведев', 'многие', 'москве', 'назад', 'накануне',\n",
    "          'нам', 'наша', 'нашей', 'наши', 'наших', 'несколько', 'но',\n",
    "          'однако', 'однако,', 'одной', 'орт', 'очень', 'первый', 'пока',\n",
    "          'поэтому', 'прежде', 'президент', 'президента', 'президентом',\n",
    "          'президенту', 'премьер', 'премьер-министр', 'премьер-министра',\n",
    "          'премьер-министром', 'премьера', 'просто', 'против', 'путин',\n",
    "          'путин,', 'путина', 'путина,', 'путину', 'путиным', 'путиным.',\n",
    "          'россией', 'россии', 'россии,', 'российские', 'российских',\n",
    "          'российского', 'российской', 'россию', 'россия', 'рф', 'свое',\n",
    "          'своего', 'своей', 'своем', 'свои', 'своим', 'своими', 'свой',\n",
    "          'сегодня', 'смотрите', 'сразу', 'среди', 'так,', 'также',\n",
    "          'такие', 'таким', 'тем', 'тех', 'то,', 'того,', 'том,', 'ходе',\n",
    "          'хотя', 'целом', 'числе', 'что', 'эта', 'этим', 'этих', 'это',\n",
    "          'этому', 'я', '–', '—']\n",
    "\n",
    "# Drop stopwords and specified words\n",
    "filtered_words = [word for word in cleaned_words if word not in stopwords and word not in todrop]\n",
    "\n",
    "# Create DataFrame from filtered words and count occurrences\n",
    "word_df = pd.DataFrame(filtered_words, columns=['word'])\n",
    "word_counts = word_df['word'].value_counts().head(50).reset_index()\n",
    "word_counts.columns = ['word', 'count']\n",
    "\n",
    "# Display the top 50 words\n",
    "topwords = list(word_counts['word'])\n",
    "print(topwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04816bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A7. Domestic stories that involve Vladimir Putin: most frequent words\n",
    "\n",
    "# Filter dataframe for rows where 'putin' is 1 and select relevant columns\n",
    "df1 = df[(df['putin'] == 1)&(df['country'] == 'ru')][['dates', 'text', 'putin']]\n",
    "\n",
    "# Extract sentences containing 'Путин'\n",
    "sentences = [''.join([sentence + '.' for sentence in text.split('.') if 'Путин' in sentence]) for text in df1['text']]\n",
    "\n",
    "# Split sentences into words\n",
    "allwords = list(itertools.chain.from_iterable([sentence.split() for sentence in sentences]))\n",
    "\n",
    "# Lowercase and remove punctuation\n",
    "cleaned_words = [word.lower().strip('.,:;«»\"') for word in allwords]\n",
    "\n",
    "# Drop stopwords and words from A6\n",
    "filtered_words = [word for word in cleaned_words if (word not in stopwords) and (word not in todrop) and (word not in topwords)]\n",
    "\n",
    "# Create DataFrame from filtered words and count occurrences\n",
    "word_df = pd.DataFrame(filtered_words, columns=['word'])\n",
    "word_counts = word_df['word'].value_counts().head(50).reset_index()\n",
    "word_counts.columns = ['word', 'count']\n",
    "\n",
    "# Display the top 50 words\n",
    "topwrodsdomestic = list(word_counts['word'])[:50]\n",
    "print(topwrodsdomestic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A8. Dictionaries\n",
    "\n",
    "# (Execution time: approximately 9 minutes)\n",
    "\n",
    "# Dictionary for 'Economics and business'\n",
    "def econ(text):\n",
    "    econ = [' налог', 'безработ', 'бизнес', 'бирж', 'валют',\n",
    "            'газпром', 'занятост', 'импорт', 'инвест', 'инфляц',\n",
    "            'капитал', 'миллиард', 'млрд', 'нефт', 'рефинансировани',\n",
    "            'санкции', 'тариф', 'торги', 'финанс', 'фонд', 'экономи', 'экспорт']\n",
    "    a = 0\n",
    "    for i in econ:\n",
    "        if i in text.lower():\n",
    "            a = 1\n",
    "    return a\n",
    "\n",
    "# Dictionary for 'National security and Russian army'\n",
    "def army(text):\n",
    "    army = [' танк ', 'армей', 'арми', 'артиллери', 'беспилотник',\n",
    "            'бомбардировщ', 'ввс', 'вдв ', 'ветеран', 'воен', 'воин', 'впк',\n",
    "            'генштаб', 'дивизи', 'зенитн', 'истребител', 'минобороны',\n",
    "            'офицер', 'парад', 'пво', 'полигон', 'рвсн', 'солдат']\n",
    "    a = 0\n",
    "    for i in army:\n",
    "        if i in text.lower():\n",
    "            a = 1\n",
    "    return a\n",
    "\n",
    "# Dictionary for 'Social welfare, healthcare, and education'\n",
    "def social(text):\n",
    "    social = ['больниц', 'вакцин', 'врач', 'егэ', 'жкх', 'заболеван', 'здравоохран',\n",
    "              'лекарств', 'медик', 'медиц', 'образовани', 'пациент', 'педагог','пенси',\n",
    "              'поликлин', 'препарат', 'социальн', 'стипенд', 'студент', 'учител']\n",
    "    a = 0\n",
    "    for i in social:\n",
    "        if i in text.lower():\n",
    "            a = 1\n",
    "    return a\n",
    "\n",
    "# Dictionary for 'Cultural, religious, and sporting events' \n",
    "def cerem(text):\n",
    "    cerem = [' кино', 'богослужен', 'искусств', 'концерт',\n",
    "             'кубок', 'культур', 'литератур', 'матч', 'музе', 'награжд',\n",
    "             'олимпи', 'парад ', 'православ', 'праздн', 'режиссер', 'сборная',\n",
    "             'соревнован', 'спортив', 'театр', 'турнир',\n",
    "             'феставал', 'фильм', 'худож',\n",
    "             'церемон', 'чемпион', 'шоу', 'юбиле']\n",
    "    a = 0\n",
    "    for i in cerem:\n",
    "        if i in text.lower():\n",
    "            a = 1\n",
    "    return a\n",
    "\n",
    "# Create columns that equal 1 if the text includes words from the dictionary\n",
    "\n",
    "df['econ'] = [econ(i) for i in df['text']]\n",
    "df['army'] = [army(i) for i in df['text']]\n",
    "df['social'] = [social(i) for i in df['text']]\n",
    "df['cerem'] = [cerem(i) for i in df['text']]\n",
    "\n",
    "# Function to change values in a column to 1 if they are higher than 0\n",
    "def change_value(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "# Create category 'covered' that equals 1 if the text includes words from any dictionary\n",
    "\n",
    "df['covered'] = df['econ'] + df['army'] + df['social'] + df['cerem']\n",
    "# Apply the function to the column\n",
    "df['covered'] = df['covered'].apply(change_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A8. Dictionaries\n",
    "# Table in A8\n",
    "\n",
    "# Sampling: randomly selecting stories to estimate the accuracy of the dictionaries\n",
    "\n",
    "# Only domestic select stories that mention Putin\n",
    "dfp = df[(df['putin'] == 1) & (df['country'] == 'ru')]\n",
    "\n",
    "# This sample will be used in A8 in the appendix -- accuracy\n",
    "sample = dfp.sample(n = 50, random_state = 42)\n",
    "# Keep only necessary columns -- sample to estimate accuracy\n",
    "sample = sample[['dates', 'text', 'econ', 'army', 'social', 'cerem', 'covered']]\n",
    "\n",
    "# Display the first few rows\n",
    "sample.head()\n",
    "\n",
    "# The code below can be used to save the sample to .csv\n",
    "# sample.to_csv(\"insert a path here\")\n",
    "\n",
    "# Check if the text is the same as in validation file\n",
    "print(\"Same as validation file?\", list(ad['text']) == list(sample['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1246b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A8. Dictionaries\n",
    "# Table in A8\n",
    "\n",
    "# Check if the validations results are the same as dictionary results (full accuracy)\n",
    "# referred as '1. Accuracy (all dictionaries) that equals to 1'\n",
    "# c1 are results form coder 1, c2 are from coder 2\n",
    "\n",
    "conditions = [\n",
    "    (ad['c1_econ'] == ad['c2_econ']) & (ad['c1_econ'] == ad['econ']),\n",
    "    (ad['c1_army'] == ad['c2_army']) & (ad['c1_army'] == ad['army']),\n",
    "    (ad['c1_social'] == ad['c2_social']) & (ad['c1_social'] == ad['social']),\n",
    "    (ad['c1_cerem'] == ad['c2_cerem']) & (ad['c1_cerem'] == ad['cerem']),\n",
    "    (ad['c1_covered'] == ad['c2_covered']) & (ad['c1_covered'] == ad['covered'])\n",
    "]\n",
    "\n",
    "# Combine all conditions\n",
    "all_conditions = all([condition.all() for condition in conditions])\n",
    "\n",
    "# Print the result\n",
    "print(\"All conditions are True:\", all_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A8. Dictionaries\n",
    "# Table in A8\n",
    "\n",
    "# Randomly selecting stories to estimate the precision of the dictionaries\n",
    "\n",
    "# This sample will be used in A8 in the appendix -- precision\n",
    "\n",
    "# Function to sample entries based on a column filter\n",
    "def sample_entries(df, column):\n",
    "    filtered_df = df[df[column] == 1]  # Filter rows where column value is 1\n",
    "    return filtered_df.sample(20, random_state = 42)  # Randomly sample n entries\n",
    "\n",
    "# Sample entries for each category\n",
    "econ_sample = sample_entries(dfp, 'econ')\n",
    "army_sample = sample_entries(dfp, 'army')\n",
    "social_sample = sample_entries(dfp, 'social')\n",
    "cerem_sample = sample_entries(dfp, 'cerem')\n",
    "\n",
    "# Stack the samples vertically\n",
    "dct_prec = pd.concat([econ_sample, army_sample, social_sample, cerem_sample], ignore_index=True)\n",
    "# Keep only necessary columns -- sample to estimate accuracy\n",
    "sample = dct_prec[['dates', 'text', 'econ', 'army', 'social', 'cerem']]\n",
    "\n",
    "# Display the first few rows\n",
    "sample.head()\n",
    "\n",
    "# Check if the text is the same as in validation file\n",
    "print(\"Same as validation file?\", list(pdi['text']) == list(sample['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A8. Dictionaries\n",
    "# Table in A8\n",
    "\n",
    "# Check if the validations results are the same as dictionary results (full accuracy)\n",
    "# c1 are results form coder 1, c2 are from coder 2\n",
    "\n",
    "conditions = [\n",
    "    (pdi['c1_econ'] == pdi['c2_econ']) ,\n",
    "    (pdi['c1_army'] == pdi['c2_army']) ,\n",
    "    (pdi['c1_social'] == pdi['c2_social']) ,\n",
    "    (pdi['c1_cerem'] == pdi['c2_cerem']) \n",
    "]\n",
    "\n",
    "# Combine all conditions\n",
    "all_conditions = all([condition.all() for condition in conditions])\n",
    "\n",
    "# Print the result\n",
    "print(\"All conditions are True:\", all_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A8. Dictionaries\n",
    "# Table in A8\n",
    "\n",
    "# Define a list of dictionaries to iterate through\n",
    "dictionaries = ['econ', 'army', 'social', 'cerem']\n",
    "\n",
    "# Calculate and print precision for each dictionary\n",
    "for dictionary in dictionaries:\n",
    "    subset = pdi[pdi['dictionary'] == dictionary]\n",
    "    precision = (subset[dictionary] == subset[f'c1_{dictionary}']).mean()\n",
    "    print(f\"Precision {dictionary}, {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127041b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in the article (section 'Subjects of the Stories')\n",
    "\n",
    "# \" Although the themes frequently overlapped and certain stories did not cover any of the themes,\n",
    "#   this approach helped me label 84% of domestic stories that mention the ruler \"\n",
    "\n",
    "# Filtering the DataFrame\n",
    "dfp = df[(df['putin'] == 1) & (df['country'] == 'ru')]\n",
    "\n",
    "# Calculating the required value\n",
    "result = round(dfp['covered'].sum() / dfp.shape[0], 2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A9. Counts of mentions of other politicians: co-opted parties and opposition\n",
    "# (Execution time: approximately 5 minutes)\n",
    "\n",
    "def count_name_occurrences(name):\n",
    "    \"\"\"\n",
    "    Count the number of times a name appears in the specified column of the DataFrame.\n",
    "    \"\"\"\n",
    "    return df['text'].apply(lambda x: 1 if name in x else 0).sum()\n",
    "\n",
    "names = ['Путин', 'Абрамович', 'Авен', 'Аксенов', 'Аксёнов', 'Алекперов',\n",
    "         'Багапш', 'Бастыркин', 'Батурин', 'Белавенцев',\n",
    "         'Березовск', 'Бородае', 'Бородай', 'Бородаю', 'Бородая',\n",
    "         'Бортников', 'Верзилов', 'Володин', 'Волошин', 'Герасимов',\n",
    "         'Гиркин', 'Глазьев', 'Голодец', 'Греф', 'Грызлов', 'Гудков',\n",
    "         'Дворкович', 'Делимханов', 'Дерипаск', 'Евтушенков', 'Жданов',\n",
    "         'Жириновск', 'Золотов', 'Зубков', 'Зюганов', 'Илларионов',\n",
    "         'Кадыров', 'Кара-Мурз', 'Каспаров', 'Касьянов',\n",
    "         'Ковальчук', 'Кудрин', 'Лавров',\n",
    "         'Лесин', 'Лимонов', 'Литвиненко', 'Лужков', 'Медведев',\n",
    "         'Миллер', 'Навальн', 'Нарышкин', 'Немцов', 'Новодворск',\n",
    "         'Патрушев', 'Песков', 'Полтавченко', 'Потанин', 'Примаков',\n",
    "         'Прохоров', 'Ресин', 'Ройзман', 'Ролдугин', 'Ротенберг',\n",
    "         'Сердюков', 'Сечин', 'Силуанов', 'Соболь', 'Собчак',\n",
    "         'Собянин', 'Стрелков', 'Сурков', 'Тимченко',\n",
    "         'Толоконников', 'Удальцов', 'Улюкаев', 'Устинов',\n",
    "         'Фрадков', 'Фридман', 'Ходорковск', 'Чайка',\n",
    "         'Чайке', 'Чайки', 'Чайкой', 'Чемезов', 'Черкесов', \n",
    "         'Чубайс', 'Чуров', 'Шевкунов', 'Шлосберг', 'Шойгу',\n",
    "         'Шувалов', 'Эрнст', 'Якименко', 'Якунин', 'Ярмыш']\n",
    "\n",
    "for name in names:\n",
    "    print(name, \":\", count_name_occurrences(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix A10. Themes (topics) in domestic news that refer to Vladimir Putin\n",
    "\n",
    "# Subsetting to stories that only involve Putin\n",
    "a10 = df[(df['putin'] == 1) & (df['country'] == 'ru')]\n",
    "\n",
    "# Applying dictionaries to data from each term separately\n",
    "\n",
    "print('Econ', 'Social', 'Security','Culture', 'Total')\n",
    "for term in [1, 2, 'Medvedev', 3, 4]:\n",
    "    dat = a10[a10['term'] == term]\n",
    "    print(term, dat['econ'].sum(), dat['social'].sum(), dat['army'].sum(), dat['cerem'].sum(), dat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below can be used to save the corpus into feather format\n",
    "# this was required to make the file readable in R\n",
    "# the newsmap_training.R uses corpus.feather as an imput file\n",
    "\n",
    "# Leave only dates and text as 'country' will be assigned by Newsmap\n",
    "df1 = df[['dates', 'text']]\n",
    "# Drop 'Putin' from the text, as 'Putin' is not supposed to be a predictor of country-topic for the classifier\n",
    "for i in range(len(df1)):\n",
    "    df1.loc[i, 'text'] = df1.loc[i, 'text'].replace('Путин', '')\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct the path to the corpus.pkl file\n",
    "corpus_feather_path = os.path.join(current_directory, \"corpus.feather\")\n",
    "#print(corpus_feather_path)\n",
    "\n",
    "# Save the file\n",
    "\n",
    "df1.to_feather(corpus_feather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35770215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
